{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from model.seq2seq import Encoder, Decoder, Seq2Seq\n",
    "from utils.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from model.seq2seq import Encoder, Decoder, Seq2Seq\n",
    "from utils.tokenizer import Tokenizer\n",
    "\n",
    "# Configurações de dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Tokenizer e Dados de Treinamento\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.build_vocab([\n",
    "    \"oi\", \"olá!\", \"tudo bem?\", \"estou bem, obrigado.\",\n",
    "    \"qual seu nome?\", \"sou seu assistente.\"\n",
    "])\n",
    "\n",
    "pairs = [\n",
    "    (\"oi\", \"olá!\"),\n",
    "    (\"tudo bem?\", \"estou bem, obrigado.\"),\n",
    "    (\"qual seu nome?\", \"sou seu assistente.\"),\n",
    "]\n",
    "\n",
    "def tensorize(pair):\n",
    "    src = torch.tensor([tokenizer.word2idx['<sos>']] + tokenizer.encode(pair[0]) + [tokenizer.word2idx['<eos>']])\n",
    "    trg = torch.tensor([tokenizer.word2idx['<sos>']] + tokenizer.encode(pair[1]) + [tokenizer.word2idx['<eos>']])\n",
    "    return src, trg\n",
    "\n",
    "data = [tensorize(p) for p in pairs]\n",
    "\n",
    "# Criar o DataLoader\n",
    "class ChatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def collate(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
    "    trg_batch = pad_sequence(trg_batch, batch_first=True, padding_value=0)\n",
    "    return src_batch, trg_batch\n",
    "\n",
    "loader = DataLoader(ChatDataset(data), batch_size=2, collate_fn=collate)\n",
    "\n",
    "# Definição do Modelo\n",
    "INPUT_DIM = OUTPUT_DIM = len(tokenizer.word2idx)\n",
    "EMB_DIM = 64\n",
    "HID_DIM = 128\n",
    "\n",
    "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM).to(device)\n",
    "dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM).to(device)\n",
    "model = Seq2Seq(enc, dec).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# Loop de treinamento\n",
    "EPOCHS = 100\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg in loader:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        loss = criterion(output[:, 1:].reshape(-1, output_dim), trg[:, 1:].reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}: Loss = {epoch_loss:.4f}\")\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "torch.save(model.state_dict(), \"model/checkpoints/seq2seq.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from model.seq2seq import Encoder, Decoder, Seq2Seq\n",
    "from utils.tokenizer import Tokenizer\n",
    "\n",
    "# Configurações de dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Tokenizer e Dados de Treinamento\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.build_vocab([\n",
    "    \"oi\", \"olá!\", \"tudo bem?\", \"estou bem, obrigado.\",\n",
    "    \"qual seu nome?\", \"sou seu assistente.\"\n",
    "])\n",
    "\n",
    "pairs = [\n",
    "    (\"oi\", \"olá!\"),\n",
    "    (\"tudo bem?\", \"estou bem, obrigado.\"),\n",
    "    (\"qual seu nome?\", \"sou seu assistente.\"),\n",
    "]\n",
    "\n",
    "def tensorize(pair):\n",
    "    src = torch.tensor([tokenizer.word2idx['<sos>']] + tokenizer.encode(pair[0]) + [tokenizer.word2idx['<eos>']])\n",
    "    trg = torch.tensor([tokenizer.word2idx['<sos>']] + tokenizer.encode(pair[1]) + [tokenizer.word2idx['<eos>']])\n",
    "    return src, trg\n",
    "\n",
    "data = [tensorize(p) for p in pairs]\n",
    "\n",
    "# Criar o DataLoader\n",
    "class ChatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def collate(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
    "    trg_batch = pad_sequence(trg_batch, batch_first=True, padding_value=0)\n",
    "    return src_batch, trg_batch\n",
    "\n",
    "loader = DataLoader(ChatDataset(data), batch_size=2, collate_fn=collate)\n",
    "\n",
    "# Definição do Modelo\n",
    "INPUT_DIM = OUTPUT_DIM = len(tokenizer.word2idx)\n",
    "EMB_DIM = 64\n",
    "HID_DIM = 128\n",
    "\n",
    "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM).to(device)\n",
    "dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM).to(device)\n",
    "model = Seq2Seq(enc, dec).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# Loop de treinamento\n",
    "EPOCHS = 100\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg in loader:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        loss = criterion(output[:, 1:].reshape(-1, output_dim), trg[:, 1:].reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}: Loss = {epoch_loss:.4f}\")\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "torch.save(model.state_dict(), \"model/checkpoints/seq2seq.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Inicia a captura da webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detecta rostos e estima idade/gênero\n",
    "    try:\n",
    "        result = DeepFace.analyze(frame, actions=['age', 'gender'], enforce_detection=False)\n",
    "        for face in result:\n",
    "            x, y, w, h = face['region'].values()\n",
    "            age = face['age']\n",
    "            gender = face['dominant_gender']\n",
    "\n",
    "            # Desenha o retângulo e as informações\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "            cv2.putText(frame, f\"{gender}, {age}\", (x, y-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "    except Exception as e:\n",
    "        print(\"Erro:\", e)\n",
    "\n",
    "    cv2.imshow(\"Webcam - Age & Gender\", frame)\n",
    "\n",
    "    # Tecla 'q' para sair\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
